k8sServiceHost: 10.4.0.40
k8sServicePort: 6443

debug:
  enabled: false
rbac:
  create: true
cluster:
  name: default
name: cilium
rollOutCiliumPods: true
image:
  repository: quay.io/cilium/cilium
  pullPolicy: IfNotPresent
  useDigest: true

# Necessary for Kubernetes v1.24+
securityContext:
  privileged: true
  capabilities:
    ciliumAgent: "{CHOWN,KILL,NET_ADMIN,NET_RAW,IPC_LOCK,SYS_ADMIN,SYS_RESOURCE,DAC_OVERRIDE,FOWNER,SETGID,SETUID}"
    cleanCiliumState: "{NET_ADMIN,SYS_ADMIN,SYS_RESOURCE}"
  cgroup:
    hostRoot: "/sys/fs/cgroup"
    autoMount:
      enabled: false

tolerations:
- operator: Exists

# Required to be disabled on Raspbian; breaks shit
l7Proxy: false

podDisruptionBudget:
  enabled: true
  maxUnavailable: 2

updateStrategy:
  rollingUpdate:
    maxUnavailable: 2
  type: RollingUpdate

bpf:
  clockProbe: false
  preallocateMaps: false
  lbMapMax: 65536
  policyMapMax: 16384
  monitorAggregation: medium
  monitorInterval: "5s"
  monitorFlags: "all"
  lbExternalClusterIP: false

cleanBpfState: false
cleanState: false
cni:
  install: true
  chainingMode: none
  exclusive: true
  customConf: false
  confPath: /etc/cni/net.d
  binPath: /opt/cni/bin
  configMapKey: cni-config
  confFileMountPath: /tmp/cni-configuration
  hostConfDirMountPath: /host/etc/cni/net.d

containerRuntime:
  integration: none

customCalls:
  enabled: false

datapathMode: veth
encryption:
  enabled: false
  type: wireguard
  wireguard:
    userspaceFallback: false

healthChecking: true
healthPort: 9876
hostFirewall:
  enabled: false
hostPort:
  enabled: false

hostServices:
  enabled: false
  protocols: tcp,udp

hubble:
  enabled: false
  # TODO: Fix this. Sad.
  tls:
    auto:
      method: cronJob
  relay:
    enabled: false
    # TODO: Fix this. Sad.
  ui:
    enabled: false
    # TODO: Fix this. Sad.
    standalone:
      enabled: false
    rollOutPods: true
    replicas: 2
    updateStrategy:
      rollingUpdate:
        maxUnavailable: 1
      type: RollingUpdate

    securityContext:
      enabled: true

    ingress:
      enabled: false

identityAllocationMode: "crd"

installIptablesRules: true

installNoConntrackIptablesRules: false

ipam:
  mode: "cluster-pool"
  operator:
    clusterPoolIPv4PodCIDRList: ["10.244.0.0/16"]
    clusterPoolIPv4MaskSize: 24

ipMasqAgent:
  enabled: false

ipv4:
  enabled: true

egressGateway:
  enabled: false

monitor:
  enabled: false

nodePort:
  enabled: false
  bindProtection: true
  autoProtectPortRange: true
  enableHealthCheck: true

policyEnforcementMode: "default"
pprof:
  enabled: false

prometheus:
  enabled: false
  port: 9090
  serviceMonitor:
    enabled: false
    labels: {}
  metrics: ~

proxy:
  sidecarImageRegex: "cilium/istio_proxy"
  prometheus:
    enabled: true
    port: "9095"
remoteNodeIdentity: true
resourceQuotas:
  enabled: false
  cilium:
    hard:
      pods: "10k"
  operator:
    hard:
      pods: "15"
sleepAfterInit: false
sockops:
  enabled: false
tls:
  enabled: true
  secretsBackend: local
tunnel: "vxlan"
disableEndpointCRD: false
wellKnownIdentities:
  enabled: false
operator:
  enabled: true
  rollOutPods: true
  replicas: 2
  serviceAccountName: cilium-operator
