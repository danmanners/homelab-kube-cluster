---
monitoring:
  enabled: true
  createPrometheusRules: true

ingress:
  enabled: false

configOverride: |
  [global]
  bdev_enable_discard = true
  bdev_async_discard = true

cephClusterSpec:
  network:
    provider: host
  crashCollector:
    disable: false
  dashboard:
    enabled: true
    urlPrefix: /
    ssl: false
  storage:
    useAllNodes: false
    useAllDevices: false
    config:
      osdsPerDevice: "1"
    nodes:
      - name: talos-cp02
        devices:
          - name: "/dev/disk/by-id/ata-WDC_WDS250G2B0B_2014GX459412"
      - name: talos-wn01
        devices:
          - name: "/dev/disk/by-id/nvme-Sabrent_9128071116F600059080"

# Don't need Block Pools
cephBlockPools: []

# Don't need ObjectStores
cephObjectStores: []

cephFileSystems:
  - name: ceph-filesystem
    spec:
      metadataPool:
        replicated:
          size: 2
      dataPools:
        - failureDomain: host
          replicated:
            size: 2
          name: data0
      metadataServer:
        activeCount: 1
        activeStandby: true
        resources:
          requests:
            cpu: 1000m
            memory: 4Gi
          limits:
            memory: 4Gi
    storageClass:
      enabled: true
      isDefault: false
      name: ceph-filesystem
      pool: data0
      reclaimPolicy: Delete
      allowVolumeExpansion: true
      parameters:
        csi.storage.k8s.io/provisioner-secret-name: rook-csi-cephfs-provisioner
        csi.storage.k8s.io/provisioner-secret-namespace: rook-ceph
        csi.storage.k8s.io/controller-expand-secret-name: rook-csi-cephfs-provisioner
        csi.storage.k8s.io/controller-expand-secret-namespace: rook-ceph
        csi.storage.k8s.io/node-stage-secret-name: rook-csi-cephfs-node
        csi.storage.k8s.io/node-stage-secret-namespace: rook-ceph
        csi.storage.k8s.io/fstype: xfs
